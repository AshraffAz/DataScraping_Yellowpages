{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c00f489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Category     Abbrv  Amount of URLS  \\\n",
      "0  Business Support and Supplies       bss           24473   \n",
      "1            Cars and Automotive      cars           11698   \n",
      "2   Construction and Engineering        CE           24827   \n",
      "3       Computer and Electronics  computer            9187   \n",
      "4        Fashion and Accessories       F&A            7020   \n",
      "5      Healthcare and Medication       H&M           13836   \n",
      "6               Home and Living        H&L           16913   \n",
      "7                 Retail Stores     retail           12001   \n",
      "8             Sports and Hobbies    sports            1655   \n",
      "9      Trading and Manufacturing   trading           12001   \n",
      "\n",
      "   URLS last search index  Amount of Data  Data last search index  \\\n",
      "0                   24473           21116                     NaN   \n",
      "1                    3160            3000                     NaN   \n",
      "2                   24827           24821                 24821.0   \n",
      "3                    4502            4500                     NaN   \n",
      "4                    5002            4999                     NaN   \n",
      "5                    3002            2996                     NaN   \n",
      "6                    3002            3000                     NaN   \n",
      "7                    7002            6992                     NaN   \n",
      "8                    1655            1651                     NaN   \n",
      "9                    3502            3499                     NaN   \n",
      "\n",
      "   Amount of Cleaned Email Data  \n",
      "0                           NaN  \n",
      "1                           NaN  \n",
      "2                        3934.0  \n",
      "3                           NaN  \n",
      "4                           NaN  \n",
      "5                           NaN  \n",
      "6                           NaN  \n",
      "7                           NaN  \n",
      "8                           NaN  \n",
      "9                           NaN  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import undetected_chromedriver as uc\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "\n",
    "df_records = pd.read_csv('Category_Tracking.csv')\n",
    "print(df_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981eb832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11698\n",
      "Current Saved Index 4993\n",
      "Failed to retrieve webpage for index 4994.\n",
      "Current Saved Index 4997\n",
      "Failed to retrieve webpage for index 4998.\n",
      "Current Saved Index 5836\n",
      "Failed to retrieve webpage for index 5837.\n",
      "\n",
      "Failed to retrieve webpage for index 5838.\n",
      "Current Saved Index 5840\n",
      "Failed to retrieve webpage for index 5841.\n",
      "\n",
      "Failed to retrieve webpage for index 5842.\n",
      "Current Saved Index 5848\n",
      "Failed to retrieve webpage for index 5849.\n",
      "\n",
      "Failed to retrieve webpage for index 5850.\n",
      "Current Saved Index 5851\n",
      "Failed to retrieve webpage for index 5852.\n",
      "\n",
      "Failed to retrieve webpage for index 5853.\n",
      "\n",
      "Failed to retrieve webpage for index 5854.\n",
      "\n",
      "Failed to retrieve webpage for index 5855.\n",
      "Current Saved Index 5861\n",
      "Failed to retrieve webpage for index 5862.\n",
      "Current Saved Index 5863\n",
      "Failed to retrieve webpage for index 5864.\n",
      "Current Saved Index 5980\n",
      "Failed to retrieve webpage for index 5981.\n",
      "\n",
      "Failed to retrieve webpage for index 5982.\n",
      "Current Saved Index 5983\n",
      "Failed to retrieve webpage for index 5984.\n",
      "Current Saved Index 5985\n",
      "Failed to retrieve webpage for index 5986.\n",
      "Current Saved Index 5988\n",
      "Failed to retrieve webpage for index 5989.\n",
      "Current Saved Index 5991\n",
      "Failed to retrieve webpage for index 5992.\n",
      "Current Saved Index 8103\n",
      "Failed to retrieve webpage for index 8104.\n",
      "Current Saved Index 8136\n",
      "Failed to retrieve webpage for index 8137.\n",
      "Current Saved Index 8383\n",
      "Failed to retrieve webpage for index 8384.\n",
      "Current Saved Index 8425\n",
      "Failed to retrieve webpage for index 8426.\n",
      "Current Saved Index 8760\n",
      "Failed to retrieve webpage for index 8761.\n",
      "Current Saved Index 8837\n",
      "Failed to retrieve webpage for index 8838.\n",
      "Current Saved Index 8989\n",
      "Failed to retrieve webpage for index 8990.\n",
      "Current Saved Index 9133\n",
      "Failed to retrieve webpage for index 9134.\n",
      "Current Saved Index 9895\n",
      "Failed to retrieve webpage for index 9896.\n",
      "\n",
      "Failed to retrieve webpage for index 9897.\n",
      "\n",
      "Failed to retrieve webpage for index 9898.\n",
      "Current Saved Index 9899\n",
      "Failed to retrieve webpage for index 9900.\n",
      "Current Saved Index 10725\n",
      "Failed to retrieve webpage for index 10726.\n",
      "Current Saved Index 11128\n",
      "Failed to retrieve webpage for index 11129.\n",
      "\n",
      "Failed to retrieve webpage for index 11130.\n",
      "\n",
      "Failed to retrieve webpage for index 11131.\n",
      "Current Saved Index 11388\n",
      "Failed to retrieve webpage for index 11389.\n",
      "\n",
      "Failed to retrieve webpage for index 11390.\n",
      "\n",
      "Failed to retrieve webpage for index 11391.\n",
      "\n",
      "Failed to retrieve webpage for index 11392.\n",
      "\n",
      "Failed to retrieve webpage for index 11393.\n",
      "\n",
      "Failed to retrieve webpage for index 11394.\n",
      "\n",
      "Failed to retrieve webpage for index 11395.\n",
      "Appended data for 8492 companies to the CSV file.\n",
      "Total time taken: 19012.258774280548 seconds.\n",
      "                        Category     Abbrv  Amount of URLS  \\\n",
      "0  Business Support and Supplies       bss           24473   \n",
      "1            Cars and Automotive      cars           11698   \n",
      "2   Construction and Engineering        CE           24827   \n",
      "3       Computer and Electronics  computer            9187   \n",
      "4        Fashion and Accessories       F&A            7020   \n",
      "5      Healthcare and Medication       H&M           13836   \n",
      "6               Home and Living        H&L           16913   \n",
      "7                 Retail Stores     retail           12001   \n",
      "8             Sports and Hobbies    sports            1655   \n",
      "9      Trading and Manufacturing   trading           12001   \n",
      "\n",
      "   URLS last search index  Amount of Data  Data last search index  \\\n",
      "0                   24473           21116                 21116.0   \n",
      "1                   11698           11491                     NaN   \n",
      "2                   24827           24821                 24821.0   \n",
      "3                    4502            4500                     NaN   \n",
      "4                    5002            4999                     NaN   \n",
      "5                    3002            2996                     NaN   \n",
      "6                    3002            3000                     NaN   \n",
      "7                    7002            6992                     NaN   \n",
      "8                    1655            1651                     NaN   \n",
      "9                    3502            3499                     NaN   \n",
      "\n",
      "   Amount of Cleaned Email Data  \n",
      "0                       20788.0  \n",
      "1                           NaN  \n",
      "2                        3934.0  \n",
      "3                           NaN  \n",
      "4                           NaN  \n",
      "5                           NaN  \n",
      "6                           NaN  \n",
      "7                           NaN  \n",
      "8                           NaN  \n",
      "9                           NaN  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_records = pd.read_csv('Category_Tracking.csv')\n",
    "url_csv_filename = lambda abbrv: \"yellowpages_urls_\" + abbrv + \".csv\"\n",
    "data_csv_filename = lambda abbrv: \"yellowpages_data_\" + abbrv + \".csv\"\n",
    "cleaned_csv_filename = lambda abbrv: \"cleaned_\" + abbrv + \".csv\"\n",
    "\n",
    "tasks = [\n",
    "    {'category':1, 'num':9000},\n",
    "]\n",
    "\n",
    "def scrape_data(category,num):\n",
    "    start_time = time.time()\n",
    "    category_data = df_records.loc[category]\n",
    "    start_index = category_data[\"URLS last search index\"] +1\n",
    "    end_index = start_index + num if start_index + num < category_data[\"Amount of URLS\"] else category_data[\"Amount of URLS\"]\n",
    "    print(end_index)\n",
    "    df = pd.read_csv(url_csv_filename(category_data['Abbrv']))\n",
    "    companies_data = []\n",
    "    \n",
    "    \n",
    "    # Iterate over the specified range of indices in the DataFrame\n",
    "    for index in range(start_index, end_index - 2):\n",
    "        url = df.loc[index, 'Company Profile URL']\n",
    "\n",
    "        # Define headers to mimic a browser\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.6099.110 Safari/537.36',\n",
    "            'Referer': 'https://www.yellowpages.my/services/l/business-support-supplies'\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.ok:\n",
    "            # Create a BeautifulSoup object and specify the parser\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Define CSS selectors\n",
    "            title_selector = 'div.title.yp-h2'\n",
    "            telephone_selector = 'body > app-root > div > app-root > app-profile > div > div > div.right > div.info.ng-star-inserted > div.map > div > div.item.address-cont > div > div > div > div > a:nth-child(1)'\n",
    "            email_selector = 'body > app-root > div > app-root > app-profile > div > div > div.right > div.info.ng-star-inserted > div.map > div > div.item.address-cont > div > div > div > div > a:nth-child(2)'\n",
    "\n",
    "            # Extract data using selectors\n",
    "            company_title = soup.select_one(title_selector).text.strip() if soup.select_one(title_selector) else 'Not found'\n",
    "            telephone_number = soup.select_one(telephone_selector).text.strip() if soup.select_one(telephone_selector) else 'Not found'\n",
    "            email_address = soup.select_one(email_selector).text.strip() if soup.select_one(email_selector) else 'Not found'\n",
    "\n",
    "            # Append the data to the list\n",
    "            companies_data.append({\n",
    "                'Company Name': company_title,\n",
    "                'Email': email_address,\n",
    "                'Telephone': telephone_number\n",
    "            })\n",
    "            \n",
    "            print(f\"Current Saved Index {index}\", end = \"\\r\")\n",
    "        else:\n",
    "            print(f\"\\nFailed to retrieve webpage for index {index}.\")\n",
    "\n",
    "        # Add a delay to avoid being blocked or to mimic human interaction\n",
    "        time.sleep(1)\n",
    "        \n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    new_companies_df = pd.DataFrame(companies_data)\n",
    "\n",
    "    # End the timer\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "\n",
    "    # Append this data to the existing CSV file\n",
    "    new_companies_df.to_csv(data_csv_filename(category_data['Abbrv']), mode='a', header=False, index=False)\n",
    "\n",
    "    print(f\"Appended data for {len(companies_data)} companies to the CSV file.\")\n",
    "    print(f\"Total time taken: {total_time} seconds.\")\n",
    "    df_records.loc[category,'URLS last search index'] = end_index\n",
    "    df_records.loc[category,'Amount of Data'] = len(pd.read_csv(data_csv_filename(category_data['Abbrv'])))\n",
    "    df_records.to_csv('Category_Tracking.csv', index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "for task in tasks:\n",
    "    scrape_data(task['category'],task['num'])\n",
    "\n",
    "df_records = pd.read_csv('Category_Tracking.csv')\n",
    "print(df_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ab324aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE\n"
     ]
    }
   ],
   "source": [
    "row = df_records.loc[2]\n",
    "print(row['Abbrv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b371ea67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
